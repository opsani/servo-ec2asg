#!/usr/bin/env python3
import hashlib
import sys
import os
from functools import lru_cache

import time
import boto3
import botocore.exceptions # not accessible via boto3
import yaml

import json
# 'compact' format json encode (no spaces)
json_enc = json.JSONEncoder(separators=(",",":")).encode

import adjust
from adjust import AdjustError

# FIXME: configurable wait times?
# NOTE: activity timeout may need to be set depending on the health check settings for any ELB/ALB, because aws might not put the instance into service until it passes the checks a few times in a row.
ACTIVITY_TIMEOUT = 60
INST_STATE_TIMEOUT = 120
SETTLE_TIME = 300
SETTLE_CHECK_TIME = 30

sess = boto3.session.Session() # todo: add config, e.g. region_name = ?, etc.
asg = sess.client("autoscaling")
ec2 = sess.client("ec2")

INST_TYPES=('t1.micro','t2.nano','t2.micro','t2.small','t2.medium','t2.large','t2.xlarge','t2.2xlarge','m1.small','m1.medium','m1.large','m1.xlarge','m3.medium','m3.large','m3.xlarge','m3.2xlarge','m4.large','m4.xlarge','m4.2xlarge','m4.4xlarge','m4.10xlarge','m4.16xlarge','m2.xlarge','m2.2xlarge','m2.4xlarge','cr1.8xlarge','r3.large','r3.xlarge','r3.2xlarge','r3.4xlarge','r3.8xlarge','r4.large','r4.xlarge','r4.2xlarge','r4.4xlarge','r4.8xlarge','r4.16xlarge','x1.16xlarge','x1.32xlarge','x1e.xlarge','x1e.2xlarge','x1e.4xlarge','x1e.8xlarge','x1e.16xlarge','x1e.32xlarge','i2.xlarge','i2.2xlarge','i2.4xlarge','i2.8xlarge','i3.large','i3.xlarge','i3.2xlarge','i3.4xlarge','i3.8xlarge','i3.16xlarge','i3.metal','hi1.4xlarge','hs1.8xlarge','c1.medium','c1.xlarge','c3.large','c3.xlarge','c3.2xlarge','c3.4xlarge','c3.8xlarge','c4.large','c4.xlarge','c4.2xlarge','c4.4xlarge','c4.8xlarge','c5.large','c5.xlarge','c5.2xlarge','c5.4xlarge','c5.9xlarge','c5.18xlarge','c5d.large','c5d.xlarge','c5d.2xlarge','c5d.4xlarge','c5d.9xlarge','c5d.18xlarge','cc1.4xlarge','cc2.8xlarge','g2.2xlarge','g2.8xlarge','g3.4xlarge','g3.8xlarge','g3.16xlarge','cg1.4xlarge','p2.xlarge','p2.8xlarge','p2.16xlarge','p3.2xlarge','p3.8xlarge','p3.16xlarge','d2.xlarge','d2.2xlarge','d2.4xlarge','d2.8xlarge','f1.2xlarge','f1.16xlarge','m5.large','m5.xlarge','m5.2xlarge','m5.4xlarge','m5.12xlarge','m5.24xlarge','m5d.large','m5d.xlarge','m5d.2xlarge','m5d.4xlarge','m5d.12xlarge','m5d.24xlarge','h1.2xlarge','h1.4xlarge','h1.8xlarge','h1.16xlarge',)

CFG_FILE = "./config.yaml"
CFG_SECTION = "ec2asg"

class ApiError(Exception):
    pass

class DeployError(Exception):
    pass

class ASGNotFound(DeployError):
    pass

class RefASGUnavailableException(Exception):
    def __init__(self, *args, **kwargs):
        self.original = kwargs.pop('original', None)
        super().__init__(*args)

class ConfigError(Exception): # user-provided descriptor not readable
    pass

def read_config():
    '''load the user-defined application descriptor'''

    cfg_file = os.environ.get("OPTUNE_CONFIG", CFG_FILE )
    try:
        f = open(cfg_file)
        d = yaml.load(f)
    except IOError as e:
        raise ConfigError("cannot read configuration from {}:{}".format(cfg_file,e.strerror))
    except yaml.error.YAMLError as e:
        raise ConfigError("syntax error in {}: {}".format(cfg_file,str(e)))
    # everything else: crash

    # 'new' config file
    try:
        d = d[CFG_SECTION]
        d["asg"] # access, to verify it exists
    except KeyError:
        raise ConfigError("configuration data does not contain valid data in '{}'".format(CFG_SECTION))

    return d


def get_group(name):
    a = asg.describe_auto_scaling_groups(AutoScalingGroupNames=[name])
    # describe_auto_.. doesn't fail if asg not found, check for it:
    if not a.get("AutoScalingGroups"):
        raise ASGNotFound('Auto-scaling Group "{}" does not exist'.format(name))
    return a["AutoScalingGroups"][0]


def get_asg_insts(gname):
    """get asg group description and a list of instance descriptions for all instances in the ASG. If there are instances that are in transition to InService or to Standby, this function will wait for the activity to complete before returning. This applies only to transitions that have a final state either InService or Standby. Instances that are leaving the group are not waited for are ignored (but the full list of instances is returned in all cases)."""

    retries = 3

    for retry in range(retries):
        g = get_group(gname)

        transitioning = False
        for i in g["Instances"]:
            if i["LifecycleState"] in ("Pending", "Pending:Wait", "Pending:Proceed", "EnteringStandby"):
                transitioning = True
                break

        if not transitioning:
            break

        # wait for activities and re-query
        acts=asg.describe_scaling_activities(AutoScalingGroupName=gname)
        acts = acts['Activities']
        # get only un-completed activities
        acts = [a for a in acts if a["StatusCode"] not in ('Successful','Failed','Cancelled')]
        # DEBUG
        print("waiting for ASG to complete activities (state={}, {} activities pending)".format(
            repr([i["LifecycleState"] for i in g["Instances"]]),
            len(acts)
            ), file=sys.stderr)
        wait_for_activities ( [a["ActivityId"] for a in acts] )
    else:
        raise DeployError("ASG was found in transitional state and did not complete activities after {} sec".format(ACTIVITY_TIMEOUT*retries))

    # asg_insts = { i['InstanceId'] : i for i in g["Instances"] } # here we have the ASG lifecycle status, keyed by inst. ID
    #        final = final and (a["StatusCode"] in ('Successful','Failed','Cancelled'))

    # get list of running instances
    insts = []
    inst_ids = [ i["InstanceId"] for i in g["Instances"] ]
    if not inst_ids: # no running instances, return empty
        return insts,g
    a = ec2.describe_instances(InstanceIds = inst_ids)
    for i in a["Reservations"]:
        insts.extend(i["Instances"])

    return insts,g

def q(gname):
    insts,g = get_asg_insts(gname)
    running_types = list( set( ( i["InstanceType"] for i in insts ) ) )
    # print("running instances' types:", running_types) #DEBUG

    # type defined in current launch template or launch config
    t = g.get("LaunchTemplate")
    if t:
        args = t.copy()
        args["Versions"] =  [args.pop("Version","$Default")]
        if "LaunchTemplateId" in args:
            args.pop("LaunchTemplateName",None) # keep only one of Id or Name in the args
        v = ec2.describe_launch_template_versions(**args)['LaunchTemplateVersions'][0] # should be only one
        lt_type = v["LaunchTemplateData"]["InstanceType"]
        # print("got type from Launch Template:", lt_type,file=sys.stderr)
    else: # try launch config
        lc = g.get("LaunchConfigurationName",None) # should be non-empty if there is no template!
        # FIXME assert lc
        lc = asg.describe_launch_configurations(LaunchConfigurationNames=[lc])["LaunchConfigurations"][0]
        lt_type = lc["InstanceType"]
        # print("got type from Launch config:", lt_type,file=sys.stderr)

    if len(running_types) == 0: # empty asg, return type from config
        return lt_type

    if len(running_types) != 1:
        print("multiple instance types in asg {}: {}".format(gname, repr(running_types)),file=sys.stderr)
        return "(multiple)"
    else: # len == 1
        if lt_type != running_types[0]:
            print("asg {}: instance type does {} not match running instances type {}".format(gname, lt_type, repr(running_types)),file=sys.stderr)
            return running_types[0] # return actual running type, not one from ASG

    return lt_type

def set_lt_inst_type():
    """modify launch template linked to an asg to set a new instance type. This is done by adding a new
    version to the LT."""
    raise NotImplementedError

def set_lc_inst_type():
    """modify launch configuration linked to an asg to set a new instance type. This is done by creating an entirely new
    launch configuration and setting it on the ASG (launch configs cannot be edited once created)"""
    raise NotImplementedError


def wait_for_activities(aid, progr = None):
    """wait for asg activities to complete"""

    # NOTE: the wait is done with a constant-time poll; can be improved by using StartTime and Progress to make an estimate
    # of the completion time.
    wait_time = 0
    wait_inc = 2
    while wait_time <= ACTIVITY_TIMEOUT:
# valid 'StatusCode' values: 'PendingSpotBidPlacement'|'WaitingForSpotInstanceRequestId'|'WaitingForSpotInstanceId'|'WaitingForInstanceId'|'PreInService'|'InProgress'|'WaitingForELBConnectionDraining'|'MidLifecycleAction'|'WaitingForInstanceWarmup'|'Successful'|'Failed'|'Cancelled'
        time.sleep(wait_inc)
        wait_time += wait_inc
        final = True
        r = asg.describe_scaling_activities(ActivityIds=aid)
        # print("statuses:", repr( [a["StatusCode"] for a in r["Activities"]] ), file=sys.stderr) # DEBUG
        for a in r["Activities"]:
            final = final and (a["StatusCode"] in ('Successful','Failed','Cancelled'))
        if final:
            return
        if progr:
            progr.set(float(wait_time) / ACTIVITY_TIMEOUT)
    else:
        raise Exception("wait for asg activity timed out")


def wait_for_inst_state(ilst, state, progr = None):
    wait_time = 0
    wait_inc = 2
    while True:
        time.sleep(2)
        wait_time += 2
        a = ec2.describe_instances(InstanceIds = ilst)

        insts = []
        for i in a["Reservations"]:
            insts.extend(i["Instances"])

        if all( (i["State"]["Name"] == state for i in insts) ):
            return

        # if there are instances in 'terminated' state, they won't exit that state: abort the wait
        if any( (i["State"]["Name"] == "terminated" for i in insts) ):
            raise Exception("instance(s) unexpectedly terminated")

        if wait_time > INST_STATE_TIMEOUT:
            raise Exception("wait for inst state timed out")

        if progr:
            progr.set(float(wait_time) / INST_STATE_TIMEOUT)

    # unreachable: loop is exited only via return or exception
    # return

class Progress(object):
    p = 0.0
    # p0 = 0.0 # p at start-of-stage
    parent = None

    def report(self, msg = None): # this can be replaced to change how progress updates are sent
        d = {"progress":int(round(self.p*100.0))}
        if msg:
            d["message"] = msg
        print (json_enc(d))

    def set(self, v):
        """NOTE all progress-changing methods should end up calling this"""
        if v<0.0: v = 0.0
        if v>1.0: v = 1.0
        self.p = v
        if self.parent:
            self.parent.set(self.p0 + v*self.weight)
            return
        self.report()

    def add(self, v):
        self.set(self.p + v)

    def get(self):
        return self.p

    def stage(self, weight):
        n = Progress()
        n.parent = self
        n.weight = weight
        n.p0 = self.p
        return n

    def __enter__(self):
        assert self.parent # (can't enter/exit if not created with stage()!)
        return self

    def __exit__(self, exct, excv, trace):
        assert self.parent # (can't enter/exit if not created with stage()!)
        self.parent.set(self.p0+self.weight)
        return False

# relative weights of the progress steps for each batch of instances to be updated; these are arbitrary numbers, just need to be in
# (approximate) proportion to the time taken for each step. They will be normalized to sum(weights) = 1
# at program startup
progress_weights = {
"0qry": 0.3,
"1stdby": 0.25,
"2wstdby":2.1,
"3stop":0.2,
"4wstop":44.0,
"5mod":0.1,
"6start":0.4,
"7wstart":16, # TODO: start stage might need to get an additional check stage (wait for service to be ready, e.g., check a tcp port is open)
"8svc":0.33,
"9wsvc":13.0
}
# normalize
s = sum(progress_weights.values())
progress_weights = { k:v/s for k,v in progress_weights.items() }

ASG_FINAL_STATES = ("Detaching", "Detached", "Terminating", "Terminating:Wait", "Terminating:Proceed", "Terminated")
RETRIABLE_BOTO_EXCEPTIONS = (
    botocore.exceptions.ClientError,
    botocore.exceptions.BotoCoreError,
    ASGNotFound,
)

def set_running_inst_type(gname, itype, progr, batch=1):
    """update running instances in an ASG to have a new instance type without destroying them. This is faster
    than pulling them out of the ASG and waiting for brand new ones to be created. If the ASG is empty (0 running
    instances), this function does nothing.
    Maximum 'batch' instances are stopped and removed from the ASG at the same time.
    batch cannot be more than 20.
    """

    insts,g = get_asg_insts(gname) # this will wait for any outstanding Standby<->InService transitions, returning only when all are idle or leaving the group
    progr.add(progress_weights["0qry"])
    if not insts:
        return

    asg_insts = { i['InstanceId'] : i for i in g["Instances"] } # here we have the ASG lifecycle status, keyed by inst. ID

    nbatches = (len(insts) + batch - 1) // batch
    nbatches = float(nbatches) # we'll use this in fp math, convert it now for convenience

    while insts:
        b = insts[:batch]
        insts = insts[batch:]

        # skip instances that are already the correct type or are transitioning out of the ASG permanently
        ilst = [ i["InstanceId"] for i in b if i["InstanceType"] != itype and (asg_insts[i["InstanceId"]] not in ASG_FINAL_STATES) ]
        if not ilst:
            continue

        # filter only InService instances, these need to be put into Standby
        ilst_inservice = [ i for i in ilst if asg_insts[i]['LifecycleState'] == "InService" ]
        # ilst_stdby is what needs to be returned back to InService - all that we put into standby and all that are already there
        ilst_stdby = ilst_inservice + [i for i in ilst if asg_insts[i]['LifecycleState'] == "Standby"]

        if ilst_inservice:
            r = asg.enter_standby(InstanceIds=ilst_inservice, AutoScalingGroupName = gname, ShouldDecrementDesiredCapacity = True)
            progr.add(progress_weights["1stdby"] / nbatches)
            with progr.stage(progress_weights["2wstdby"] / nbatches) as ps:
                wait_for_activities([a["ActivityId"] for a in r["Activities"]], ps)
            # TODO: double-check with describe_auto_scaling_instances and see all have LifecycleState = "Standby"

        # use try/finally to ensure we attempt to restore the instances back into the ASG, even if failures occur
        restarted = False
        try:
            # stop them
            ec2.stop_instances(InstanceIds = ilst)
            progr.add(progress_weights["3stop"] / nbatches)
            with progr.stage(progress_weights["4wstop"] / nbatches) as ps:
                wait_for_inst_state(ilst, "stopped", ps)

            # modify instance type
            for i in ilst:
                ec2.modify_instance_attribute(InstanceId = i, InstanceType = { "Value" : itype } )

            progr.add(progress_weights["5mod"] / nbatches)

            # restart them (retry ONCE, there is a rare condition where modify_instance_attribute hasn't propagated yet)
            retry = False
            try:
                ec2.start_instances(InstanceIds = ilst)
            except botocore.exceptions.ClientError as x:
                c = getattr(x,"response",{}).get("Error",{}).get("Code","")
                # we MAY get an error that is transient, something like:
                #   Invalid value 't2.nano' for instanceType. LaunchPlan instance type does not match attribute value t2.micro
                # retry once, if the error code indicates this might be the case
                if c != "InvalidParameterValue":
                    raise
                retry = True
            if retry:
                time.sleep(1)
                ec2.start_instances(InstanceIds = ilst)
            progr.add(progress_weights["6start"] / nbatches)

            with progr.stage(progress_weights["7wstart"] / nbatches) as ps:
                wait_for_inst_state(ilst, "running", ps)
            restarted = True

        finally:
            if not restarted: # an error occurred, attempt to start them (again, if needed), ignoring all errors
                rs = 0
                try:
                    ec2.start_instances(InstanceIds = ilst)
                    with progr.stage(progress_weights["7wstart"] / nbatches) as ps:
                        wait_for_inst_state(ilst, "running", ps)
                except Exception:
                    pass
                # re-query the state and warn if that fails or not everything is 'running'
                try:
                    a = ec2.describe_instances(InstanceIds = ilst)
                    tmp_insts = []
                    for i in a["Reservations"]:
                        tmp_insts.extend(i["Instances"])
                    if not all( (i["State"]["Name"] == "running" for i in tmp_insts) ):
                        print(file=sys.stderr)
                        progr.report(msg = "an error occurred during instance type update and some instances could not be restarted. They will be returned to InService state anyway, note this may cause the ASG to replace them")
                except Exception:
                    progr.report(msg = "an error occurred during instance type update and an additional error occurred when attempting to check the state of the instances. They will be returned to InService state anyway, note this may cause the ASG to replace them. In addition an error occurred ")
            # re-add back to the ASG
            r = asg.exit_standby(InstanceIds=ilst_stdby, AutoScalingGroupName = gname)
            progr.add(progress_weights["8svc"] / nbatches)
            with progr.stage(progress_weights["9wsvc"] / nbatches) as ps:
                wait_for_activities([a["ActivityId"] for a in r["Activities"]], ps)


def hash_string(s):
    # return s  # for debugging
    return hashlib.sha1(s.encode('utf-8')).hexdigest()


class A(adjust.Adjust):

    @staticmethod
    def insts_by_id(instance_ids):
        l = instance_ids
        while l:
            i = ec2.describe_instances(InstanceIds=l[:10])
            for r in i['Reservations']:
                yield from sorted(r['Instances'], key=lambda inst: inst['InstanceId'])
            l = l[10:]

    @staticmethod
    def get_cfg_asgs():
        return sorted(list(filter(str, map(lambda g: g.strip(), (cfg.get('asg') or '').split(',')))))

    @staticmethod
    def get_cfg_ref_asg():
        return cfg.get('control', {}).get('userdata', {}).get('deployment')

    @staticmethod
    def get_inst_spcs_list(insts):
        return list(map(lambda i: '{}: {};'.format(i['ImageId'], i['InstanceType']), insts))

    def get_spc_id(self, insts):
        return hash_string(' '.join(self.get_inst_spcs_list(insts)))

    @staticmethod
    def get_runt_id(insts):
        return hash_string(' '.join(map(lambda i: '{}: {};'.format(i['InstanceId'], i['State']['Name']), insts)))

    @staticmethod
    def get_runt_cnt(insts):
        return len(insts)

    @staticmethod
    def get_inst_vers_list(insts):
        return list(map(lambda i: i['ImageId'], insts))

    def get_ver_id(self, insts):
        return hash_string(''.join(self.get_inst_vers_list(insts)))

    def get_mon_inst_ids(self):
        ret = {}
        gnames = self.get_cfg_asgs()
        ref_gnames = sorted(list(filter(str, map(lambda g: g.strip(), (cfg.get('ref_asg') or '').split(',')))))
        for name in gnames:
            insts = self.get_groups_insts([name])
            insts = map(lambda i: i['InstanceId'], insts)
            ret.setdefault('instance_ids', []).extend(insts)
        for name in ref_gnames:
            insts = self.get_groups_insts([name])
            insts = map(lambda i: i['InstanceId'], insts)
            ret.setdefault('ref_instance_ids', []).extend(insts)
        return ret

    def get_target_ref_insts(self):
        ref_asg = self.get_cfg_ref_asg()
        has_ref = ref_asg is not None
        target_insts = self.get_groups_insts(self.get_cfg_asgs())
        try:
            ref_insts = self.get_groups_insts([ref_asg]) if has_ref else None
        except RETRIABLE_BOTO_EXCEPTIONS as e:
            raise RefASGUnavailableException(original=e)
        return target_insts, ref_insts

    def get_mon_spcs(self, target_insts, ref_insts):
        ret = {
            'spec_id': self.get_spc_id(target_insts),
            'runtime_id': self.get_runt_id(target_insts),
            'version_id': self.get_ver_id(target_insts),
        }
        if ref_insts:
            ret.update({
                'ref_spec_id': self.get_spc_id(ref_insts),
                'ref_runtime_id': self.get_runt_id(ref_insts),
                'ref_runtime_count': self.get_runt_cnt(ref_insts),
                'ref_version_id': self.get_ver_id(ref_insts),
            })
        return ret

    def get_group_insts(self, name):
        g = get_group(name)
        inst_ids = [i["InstanceId"] for i in g["Instances"]]
        insts = list(self.insts_by_id(inst_ids))
        return sorted(insts, key=lambda i: i['InstanceId'])

    def get_groups_insts(self, gnames):
        r = []
        for n in gnames:
            insts = self.get_group_insts(n)
            r.extend(insts)
        return sorted(r, key=lambda i: i['InstanceId'])

    def settle(self, period=SETTLE_TIME):
        target_insts0, ref_insts0 = self.get_target_ref_insts()
        mon0 = mon = self.get_mon_spcs(target_insts0, ref_insts0)  # Get initial env state for monitoring
        expired = False
        start = time.time()
        # Check-failure counters and checkboxes
        target_asgs_restarts = 0
        target_ref_version_mismatch = False
        ref_inconsistent = False
        ref_asgs_unavailable_exc = ''
        ref_asgs_updated = False
        # Settlement cycle over a period of time (arg period) every X (SETTLE_CHECK_TIME) seconds
        while not expired:
            time.sleep(SETTLE_CHECK_TIME)  # Sleep before checking again
            expired = time.time() - start >= period  # Update settlement period status (i.e. whether done or not)
            try:
                target_insts, ref_insts = self.get_target_ref_insts()
            except RefASGUnavailableException as e:
                ref_asgs_unavailable_exc = str(e.original)
                continue
            ref_asgs_unavailable_exc = ''
            mon = self.get_mon_spcs(target_insts, ref_insts)  # Get fresh env state for monitoring checks
            if mon["runtime_id"] != mon0["runtime_id"]:
                # Track multiple target asg restarts by increasing the counter and resetting runtime_id0
                # to the last retrieved target asg's runtime_id.
                target_asgs_restarts += 1
            if ref_insts:
                if mon["version_id"] != mon["ref_version_id"]:
                    target_ref_version_mismatch = True
                ref_specs_list = self.get_inst_spcs_list(ref_insts)
                ref_specs_list0 = self.get_inst_spcs_list(ref_insts0)
                ref_vers_list = self.get_inst_vers_list(ref_insts)
                ref_vers_list0 = self.get_inst_vers_list(ref_insts0)
                if ref_specs_list != ref_specs_list0 or ref_vers_list != ref_vers_list0:
                    ref_inconsistent = True
                if mon["ref_spec_id"] != mon0["ref_spec_id"]:
                    ref_asgs_updated = True
            mon0 = mon
        if target_asgs_restarts == 1:
            raise AdjustError("target asg restart detected", status="transient-failure", reason="app-restart")
        elif target_asgs_restarts > 1:
            raise AdjustError("target asg {} restarted {} times in the last {} minutes {} seconds"
                              "".format(self.get_cfg_asgs(), target_asgs_restarts, period // 60, period % 60),
                              status="rejected", reason="unstable")
        if target_ref_version_mismatch:
            raise AdjustError("Target asg(s) software version is different from one in reference asg(s).",
                              status="rejected", reason="version-mismatch")
        if ref_inconsistent:
            raise AdjustError("Reference asg(s) software version or specification is not consistent "
                              "with target asg(s).",
                              status="aborted", reason="ref-app-inconsistent")
        if ref_asgs_unavailable_exc:
            raise AdjustError("unable to query reference asg(s) for monitoring during settlement period; "
                              "exception: {}".format(ref_asgs_unavailable_exc),
                              status="aborted", reason="ref-app-unavailable")
        if ref_asgs_updated:
            raise AdjustError("application configuration was modified unexpectedly",
                              status="transient-failure", reason="app-update")
        return mon

    def query(self):
        m = self.get_mon_spcs(*self.get_target_ref_insts())
        if cfg.get('ref_asg'):
            m.update(self.get_mon_inst_ids())
        comps = {}
        desc = { "application": {"components" : comps}, "monitoring": m }
        for gname in self.get_cfg_asgs():
            t = q(gname)
            comps[gname] = { "settings" : { "inst_type" : { "value" : t, "type" : "enum", "values" : list(INST_TYPES), "unit" : "ec2" } } }
        return desc

    def adjust(self):
        groups = list(map(lambda g: g.strip(), cfg['asg'].split(',')))
        data = self.input_data["application"].get("components", {})
        # print (self.input_data, file=sys.stderr)
        lst = []
        for g in groups:
            c = data.pop(g, None)
            if not c:
                continue # no settings for this grp
            lst.append( (g, c) )
        # check for components not in 'groups'
        if data:
            # return  {"status":"failed", "message":}
            # FIXME: base class should support custom exceptions and/or allow returning data from adjust()
            raise Exception("input data contains unknown components: "+ repr(list(data.keys())))
        # FIXME: correct behavior on 'extra' data (e.g. unknown comps or unknown settings) - ignore or fail?
        progr = Progress()
        grp_weight = 1.0/float(len(lst)) # empty settings counted as well (cosmetic, will cause uneven progress advance, FIXME)
        n = 0
        for g,v in lst:
            progr.set(grp_weight * float(n))
            n = n+1
            if "settings" not in v: continue
            t = v["settings"].get("inst_type", None)
            if not t:
                continue # not set
            with progr.stage(grp_weight) as p_stage:
                set_running_inst_type(g, t["value"], p_stage, batch = cfg.get("batch_size", 1)) # TODO: check t["value"] exists

        mon = self.settle(self.input_data.get('control', {}).get('settlement'))

        return {"status":"ok", "monitoring": mon}

if __name__ == "__main__":
    # config section 'ec2asg'
    # servo-ec2asg
    try:
        cfg = read_config()
        # TODO (probably best to add to base class: check for required settings)
        i = A("1", "(todo - help text)", False)
    except Exception as x:
        raise # FIXME

    i.run()
