#!/usr/bin/env python3
import hashlib
import itertools
import sys
import os

from time import time, sleep
from threading import Timer

import boto3
import botocore.exceptions # not accessible via boto3
import yaml

import json
# 'compact' format json encode (no spaces)
json_enc = json.JSONEncoder(separators=(",",":")).encode

import adjust
from adjust import AdjustError

# FIXME: configurable wait times?
# NOTE: activity timeout may need to be set depending on the health check settings for any ELB/ALB, because aws might not put the instance into service until it passes the checks a few times in a row.
ACTIVITY_TIMEOUT = 60
INST_STATE_TIMEOUT = 120
SETTLE_TIME = 300
SETTLE_CHECK_TIME = 30

sess = boto3.session.Session(region_name="us-west-2") # todo: add config, e.g. region_name = ?, etc.
asg = sess.client("autoscaling")
ec2 = sess.client("ec2")

INST_TYPES=('t1.micro','t2.nano','t2.micro','t2.small','t2.medium','t2.large','t2.xlarge','t2.2xlarge','m1.small','m1.medium','m1.large','m1.xlarge','m3.medium','m3.large','m3.xlarge','m3.2xlarge','m4.large','m4.xlarge','m4.2xlarge','m4.4xlarge','m4.10xlarge','m4.16xlarge','m2.xlarge','m2.2xlarge','m2.4xlarge','cr1.8xlarge','r3.large','r3.xlarge','r3.2xlarge','r3.4xlarge','r3.8xlarge','r4.large','r4.xlarge','r4.2xlarge','r4.4xlarge','r4.8xlarge','r4.16xlarge','x1.16xlarge','x1.32xlarge','x1e.xlarge','x1e.2xlarge','x1e.4xlarge','x1e.8xlarge','x1e.16xlarge','x1e.32xlarge','i2.xlarge','i2.2xlarge','i2.4xlarge','i2.8xlarge','i3.large','i3.xlarge','i3.2xlarge','i3.4xlarge','i3.8xlarge','i3.16xlarge','i3.metal','hi1.4xlarge','hs1.8xlarge','c1.medium','c1.xlarge','c3.large','c3.xlarge','c3.2xlarge','c3.4xlarge','c3.8xlarge','c4.large','c4.xlarge','c4.2xlarge','c4.4xlarge','c4.8xlarge','c5.large','c5.xlarge','c5.2xlarge','c5.4xlarge','c5.9xlarge','c5.18xlarge','c5d.large','c5d.xlarge','c5d.2xlarge','c5d.4xlarge','c5d.9xlarge','c5d.18xlarge','cc1.4xlarge','cc2.8xlarge','g2.2xlarge','g2.8xlarge','g3.4xlarge','g3.8xlarge','g3.16xlarge','cg1.4xlarge','p2.xlarge','p2.8xlarge','p2.16xlarge','p3.2xlarge','p3.8xlarge','p3.16xlarge','d2.xlarge','d2.2xlarge','d2.4xlarge','d2.8xlarge','f1.2xlarge','f1.16xlarge','m5.large','m5.xlarge','m5.2xlarge','m5.4xlarge','m5.12xlarge','m5.24xlarge','m5d.large','m5d.xlarge','m5d.2xlarge','m5d.4xlarge','m5d.12xlarge','m5d.24xlarge','h1.2xlarge','h1.4xlarge','h1.8xlarge','h1.16xlarge',)

ACT_FINAL_STATUSES = ("Successful", "Failed", "Cancelled")

CFG_FILE = "./config.yaml"
CFG_SECTION = "ec2asg"

# === compute hash of arbitrary data struct
# (copied inline from skopos/.../plugins/spec_hash_helper.py)


def get_hash(data):
    """md5 hash of Python data. This is limited to scalars that are convertible to string and container
    structures (list, dict) containing such scalars. Some data items are not distinguishable, if they have
    the same representation as a string, e.g., hash(b'None') == hash('None') == hash(None)"""
    # _dbg("get_hash", data)
    hasher = hashlib.md5()
    dump_container(data, hasher.update)
    return hasher.hexdigest()


def dump_container(c, func):
    """stream the contents of a container as a string through a function
    in a repeatable order, suitable, e.g., for hashing
    """
    #
    if isinstance(c, dict): # dict
        func("{".encode('utf-8'))
        for k in sorted(c):# for all repeatable
            func("{}:".format(k).encode('utf-8'))
            dump_container(c[k], func)
            func(",".encode('utf-8'))
        func("}".encode('utf-8'))
    elif isinstance(c, list): # list
        func("[".encode('utf-8'))
        for k in c:# for all repeatable
            dump_container(k, func)
            func(",".encode('utf-8'))
        func("]".encode('utf-8'))
    else: # everything else
        if isinstance(c, type(b'')):
            pass # already a stream, keep as is
        elif isinstance(c, str):
            # encode to stream explicitly here to avoid implicit encoding to ascii
            c = c.encode('utf-8')
        else:
            c = str(c).encode('utf-8')  # convert to string (e.g., if integer)
        func(c)         # simple value, string or convertible-to-string

# ===

class ASGError(Exception):
    pass

class EC2Error(Exception):
    pass

class ASGNotFound(ASGError):
    pass

class ASGActivityTimeOutError(ASGError):
    pass

class ASGInstStateTimeOutError(ASGError):
    pass

class ASGUnavailableException(ASGError):
    def __init__(self, *args, **kwargs):
        self.original = kwargs.pop('original', None)
        super().__init__(*args)

class RefASGUnavailableException(ASGUnavailableException):
    pass

class ConfigError(Exception): # user-provided descriptor not readable
    pass

def read_config():
    '''load the user-defined application descriptor'''

    cfg_file = os.environ.get("OPTUNE_CONFIG", CFG_FILE )
    try:
        d = yaml.load(open(cfg_file))
    except IOError as e:
        raise ConfigError("cannot read configuration from {}:{}".format(cfg_file,e.strerror))
    except yaml.error.YAMLError as e:
        raise ConfigError("syntax error in {}: {}".format(cfg_file,str(e)))
    # everything else: crash

    # 'new' config file
    try:
        d = d[CFG_SECTION]
        d["asg"] # access, to verify it exists
        if len((d['asg'] if d['asg'] is not None else '').split(',')) > 1:
            assert d.get('control', {}).get('userdata', {}).get('deployment') is None, \
                'Multiple target ASG\'s in Canary mode are not supported.'
    except KeyError:
        raise ConfigError("configuration data does not contain valid data in '{}'".format(CFG_SECTION))

    return d


def get_group(name):
    a = asg.describe_auto_scaling_groups(AutoScalingGroupNames=[name])
    # describe_auto_.. doesn't fail if asg not found, check for it:
    if not a.get("AutoScalingGroups"):
        raise ASGNotFound('Auto-scaling Group "{}" does not exist'.format(name))
    return a["AutoScalingGroups"][0]


def get_insts_from_resp(a):
    return [i for r in a["Reservations"] for i in r["Instances"]]


def get_asg_insts(gname):
    """get asg group description and a list of instance descriptions for all instances in the ASG. If there are instances that are in transition to InService or to Standby, this function will wait for the activity to complete before returning. This applies only to transitions that have a final state either InService or Standby. Instances that are leaving the group are not waited for are ignored (but the full list of instances is returned in all cases)."""

    retries = 3

    for retry in range(retries):
        try:
            g = get_group(gname)
        except AWS_EXCEPTIONS as e:
            raise ASGUnavailableException(original=e)

        transitioning = any(i["LifecycleState"] in ("Pending", "Pending:Wait", "Pending:Proceed", "EnteringStandby")
                            for i in g["Instances"])
        if not transitioning:
            break

        # wait for activities and re-query
        acts = asg.describe_scaling_activities(AutoScalingGroupName=gname)['Activities']
        # get only un-completed activities
        acts = [a for a in acts if a["StatusCode"] not in ACT_FINAL_STATUSES]
        # DEBUG
        print("waiting for ASG to complete activities (state={}, {} activities pending)"
              "".format(repr([i["LifecycleState"] for i in g["Instances"]]), len(acts)),
              file=sys.stderr)
        wait_for_activities ( [a["ActivityId"] for a in acts] )
    else:
        raise ASGActivityTimeOutError("ASG was found in transitional state and did not complete activities after {} sec".format(ACTIVITY_TIMEOUT * retries))

    # asg_insts = { i['InstanceId'] : i for i in g["Instances"] } # here we have the ASG lifecycle status, keyed by inst. ID
    #        final = final and (a["StatusCode"] in ACT_FINAL_STATUSES)

    # get list of running instances
    inst_ids = [ i["InstanceId"] for i in g["Instances"] ]
    if not inst_ids: # no running instances, return empty
        return [],g
    a = ec2.describe_instances(InstanceIds = inst_ids)
    return get_insts_from_resp(a),g

def q(gname):
    insts,g = get_asg_insts(gname)
    running_types = list( set( ( i["InstanceType"] for i in insts ) ) )
    # print("running instances' types:", running_types) #DEBUG

    # type defined in current launch template or launch config
    t = g.get("LaunchTemplate")
    if t:
        args = t.copy()
        args["Versions"] =  [args.pop("Version","$Default")]
        if "LaunchTemplateId" in args:
            args.pop("LaunchTemplateName",None) # keep only one of Id or Name in the args
        v = ec2.describe_launch_template_versions(**args)['LaunchTemplateVersions'][0] # should be only one
        lt_type = v["LaunchTemplateData"]["InstanceType"]
        # print("got type from Launch Template:", lt_type,file=sys.stderr)
    else: # try launch config
        lc = g.get("LaunchConfigurationName",None) # should be non-empty if there is no template!
        # FIXME assert lc
        lc = asg.describe_launch_configurations(LaunchConfigurationNames=[lc])["LaunchConfigurations"][0]
        lt_type = lc["InstanceType"]
        # print("got type from Launch config:", lt_type,file=sys.stderr)

    if len(running_types) == 0: # empty asg, return type from config
        return lt_type

    if len(running_types) != 1:
        print("multiple instance types in asg {}: {}".format(gname, repr(running_types)),file=sys.stderr)
        return running_types[0]
        #return "(multiple)"
    elif lt_type != running_types[0]:  # len == 1
        print("asg {}: instance type does {} not match running instances type {}".format(gname, lt_type, repr(running_types)),file=sys.stderr)
        return running_types[0] # return actual running type, not one from ASG

    return lt_type


def wait_for_activities(aid, progr = None, timeout=ACTIVITY_TIMEOUT):
    """wait for asg activities to complete"""

    # NOTE: the wait is done with a constant-time poll; can be improved by using StartTime and Progress to make an estimate
    # of the completion time.
    wait_time = 0
    wait_inc = 2
    while wait_time <= timeout:
# valid 'StatusCode' values: 'PendingSpotBidPlacement'|'WaitingForSpotInstanceRequestId'|'WaitingForSpotInstanceId'|'WaitingForInstanceId'|'PreInService'|'InProgress'|'WaitingForELBConnectionDraining'|'MidLifecycleAction'|'WaitingForInstanceWarmup'|'Successful'|'Failed'|'Cancelled'
        sleep(wait_inc)
        wait_time += wait_inc
        # print("statuses:", repr( [a["StatusCode"] for a in asg.describe_scaling_activities(ActivityIds=aid)["Activities"]] ), file=sys.stderr) # DEBUG
        acts = asg.describe_scaling_activities(ActivityIds=aid)["Activities"]
        if all(a["StatusCode"] in ACT_FINAL_STATUSES for a in acts):
            return
        if progr:
            progr.set(float(wait_time) / timeout)
    raise ASGActivityTimeOutError("wait for asg activity timed out")


def wait_for_inst_state(ilst, state, progr = None):
    wait_time = 0
    wait_inc = 2
    while True:
        sleep(2)
        wait_time += wait_inc
        a = ec2.describe_instances(InstanceIds = ilst)

        if all( (i["State"]["Name"] == state for i in get_insts_from_resp(a)) ):
            return

        # if there are instances in 'terminated' state, they won't exit that state: abort the wait
        if any( (i["State"]["Name"] == "terminated" for i in get_insts_from_resp(a)) ):
            raise EC2Error("instance(s) unexpectedly terminated")

        if wait_time > INST_STATE_TIMEOUT:
            raise ASGInstStateTimeOutError('wait for inst state "{}" timed out'.format(state))

        if progr:
            progr.set(float(wait_time) / INST_STATE_TIMEOUT)

    # unreachable: loop is exited only via return or exception
    # return

class Progress(object):
    p = 0.0
    # p0 = 0.0 # p at start-of-stage
    parent = None
    last_msg = None
    timer = None

    def start_timer(self):
        self.stop_timer()
        self.timer = Timer(5, self.print_progress)
        self.timer.start()

    def stop_timer(self):
        if self.timer:
            self.timer.cancel()

    def print_progress(self):
        d = {"progress": int(round(self.p * 100.0)),
             **({"message": self.last_msg} if self.last_msg is not None else {})}
        print(json_enc(d))
        self.start_timer()

    def report(self, msg): # this can be replaced to change how progress updates are sent
        if msg:
            if self.parent:
                self.parent.report(msg)
            else:
                self.last_msg = msg

    def set(self, v):
        """NOTE all progress-changing methods should end up calling this"""
        if v<0.0: v = 0.0
        if v>1.0: v = 1.0
        self.p = v
        if self.parent:
            self.parent.set(self.p0 + v*self.weight)
            return

    def add(self, v):
        self.set(self.p + v)

    def get(self):
        return self.p

    def stage(self, weight):
        n = Progress()
        n.parent = self
        n.weight = weight
        n.p0 = self.p
        return n

    def __enter__(self):
        assert self.parent # (can't enter/exit if not created with stage()!)
        return self

    def __exit__(self, exct, excv, trace):
        assert self.parent # (can't enter/exit if not created with stage()!)
        self.parent.set(self.p0+self.weight)
        return False

# relative weights of the progress steps for each batch of instances to be updated; these are arbitrary numbers, just need to be in
# (approximate) proportion to the time taken for each step. They will be normalized to sum(weights) = 1
# at program startup
progress_weights = {
"0qry": 0.3,
"1stdby": 0.25,
"2wstdby":2.1,
"3stop":0.2,
"4wstop":44.0,
"5mod":0.1,
"6start":0.4,
"7wstart":16, # TODO: start stage might need to get an additional check stage (wait for service to be ready, e.g., check a tcp port is open)
"8svc":0.33,
"9wsvc":13.0
}
# normalize
s = sum(progress_weights.values())
progress_weights = { k:v/s for k,v in progress_weights.items() }

ASG_FINAL_STATES = ("Detaching", "Detached", "Terminating", "Terminating:Wait", "Terminating:Proceed", "Terminated")
BOTO_EXCEPTIONS = (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError,)
ASG_EXCEPTIONS = (ASGError,)
AWS_EXCEPTIONS = (*BOTO_EXCEPTIONS, *ASG_EXCEPTIONS, EC2Error)

def set_running_inst_type(gname, itype, progr, batch=1):
    """update running instances in an ASG to have a new instance type without destroying them. This is faster
    than pulling them out of the ASG and waiting for brand new ones to be created. If the ASG is empty (0 running
    instances), this function does nothing.
    Maximum 'batch' instances are stopped and removed from the ASG at the same time.
    batch cannot be more than 20.
    """

    insts,g = get_asg_insts(gname) # this will wait for any outstanding Standby<->InService transitions, returning only when all are idle or leaving the group
    progr.add(progress_weights["0qry"])
    if not insts:
        return
    if cfg.get('control', {}).get('userdata', {}).get('deployment') is not None and len(insts) >= 2:
        raise AdjustError("Cannot adjust multiple instances in a target ASG "
                          "in Canary mode. This use case is not supported at the moment.")

    asg_insts = { i['InstanceId'] : i for i in g["Instances"] } # here we have the ASG lifecycle status, keyed by inst. ID

    nbatches = float((len(insts) + batch - 1) // batch)  # we'll use this in fp math, convert it now for convenience

    while insts:
        b, insts = insts[:batch], insts[batch:]

        # skip instances that are already the correct type or are transitioning out of the ASG permanently
        ilst = [ i["InstanceId"] for i in b if i["InstanceType"] != itype and (asg_insts[i["InstanceId"]]['LifecycleState'] not in ASG_FINAL_STATES) ]
        if not ilst:
            continue

        # filter only InService instances, these need to be put into Standby
        ilst_inservice = [ i for i in ilst if asg_insts[i]['LifecycleState'] == "InService" ]
        # ilst_stdby is what needs to be returned back to InService - all that we put into standby and all that are already there
        ilst_stdby = ilst_inservice + [i for i in ilst if asg_insts[i]['LifecycleState'] == "Standby"]

        if ilst_inservice:
            r = asg.enter_standby(InstanceIds=ilst_inservice, AutoScalingGroupName = gname, ShouldDecrementDesiredCapacity = True)
            progr.add(progress_weights["1stdby"] / nbatches)
            with progr.stage(progress_weights["2wstdby"] / nbatches) as ps:
                wait_for_activities([a["ActivityId"] for a in r["Activities"]], ps)
            # TODO: double-check with describe_auto_scaling_instances and see all have LifecycleState = "Standby"

        # use try/finally to ensure we attempt to restore the instances back into the ASG, even if failures occur
        restarted = False
        try:
            # stop them
            ec2.stop_instances(InstanceIds = ilst)
            progr.add(progress_weights["3stop"] / nbatches)
            with progr.stage(progress_weights["4wstop"] / nbatches) as ps:
                wait_for_inst_state(ilst, "stopped", ps)

            # modify instance type
            for i in ilst:
                ec2.modify_instance_attribute(InstanceId = i, InstanceType = { "Value" : itype } )

            progr.add(progress_weights["5mod"] / nbatches)

            # restart them (retry ONCE, there is a rare condition where modify_instance_attribute hasn't propagated yet)
            retry = False
            try:
                ec2.start_instances(InstanceIds = ilst)
            except BOTO_EXCEPTIONS as x:
                # we MAY get an error that is transient, something like:
                #   Invalid value 't2.nano' for instanceType. LaunchPlan instance type does not match attribute value t2.micro
                # retry once, if the error code indicates this might be the case
                if getattr(x, "response", {}).get("Error", {}).get("Code", "") != "InvalidParameterValue":
                    raise
                retry = True
            if retry:
                sleep(1)
                ec2.start_instances(InstanceIds = ilst)
            progr.add(progress_weights["6start"] / nbatches)

            with progr.stage(progress_weights["7wstart"] / nbatches) as ps:
                wait_for_inst_state(ilst, "running", ps)

            restarted = True

        finally:
            start_err = None
            if not restarted: # an error occurred, attempt to start them (again, if needed), ignoring all errors
                try:
                    ec2.start_instances(InstanceIds = ilst)
                    with progr.stage(progress_weights["7wstart"] / nbatches) as ps:
                        wait_for_inst_state(ilst, "running", ps)
                except Exception:
                    pass
                # re-query the state and warn if that fails or not everything is 'running'
                try:
                    a = ec2.describe_instances(InstanceIds = ilst)
                    if not all( (i["State"]["Name"] == "running" for i in get_insts_from_resp(a)) ):
                        start_err = AdjustError("failed to start instances {}; "
                                                "an error occurred during instance type update and some instances "
                                                "could not be restarted. They will be returned to InService state anyway, "
                                                "note this may cause the ASG to replace them".format(ilst),
                                                status="failed", reason="start-failed")
                except Exception as e:
                    start_err = AdjustError("failed to start instances {}; "
                                            "an error occurred during instance type update and an additional error occurred "
                                            "when attempting to check the state of the instances. They will be returned to "
                                            "InService state anyway, note this may cause the ASG to replace them. In "
                                            "addition an error occurred: {}".format(ilst, str(e)),
                                            status="failed", reason="start-failed")
            # re-add back to the ASG
            try:
                r = asg.exit_standby(InstanceIds=ilst_stdby, AutoScalingGroupName = gname)
                progr.add(progress_weights["8svc"] / nbatches)
                with progr.stage(progress_weights["9wsvc"] / nbatches) as ps:
                    wait_for_activities([a["ActivityId"] for a in r["Activities"]], ps)
                if start_err:
                    raise start_err
                return
            except AWS_EXCEPTIONS as e:
                postfix = "previously encountered: {}".format(str(start_err)) if start_err else ""
                raise AdjustError("failed to put instances {} back in service; exception: {}; {}"
                                  "".format(ilst_stdby, str(e), postfix).strip(),
                                  status="rejected", reason="scheduling-failed")
            except Exception as e:
                postfix = "previously encountered: {}".format(str(start_err)) if start_err else ""
                raise Exception("{}; {}".format(str(e), postfix))


class App:
    def __init__(self, group_names):
        self.groups = tuple(Group(gname) for gname in group_names)

    def version_id(self):
        return get_hash(set(map(lambda group: group.version_id(), self.groups)))

    def version_ids_set(self):
        return set(itertools.chain(*(group.version_ids_set() for group in self.groups)))

    def spec_id(self):
        return get_hash(set(map(lambda group: group.spec_id(), self.groups)))

    def runtime_id(self):
        return get_hash(set(map(lambda group: group.runtime_id(), self.groups)))

    def runtime_count(self):
        return sum(group.runtime_count() for group in self.groups)

    def instance_ids(self):
        return set(itertools.chain(*(group.instance_ids() for group in self.groups)))

    def new_instances(self, prevapp):
        return self.instance_ids() - prevapp.instance_ids()

    def gone_instances(self, tracking_insts):
        return tracking_insts - self.instance_ids()


class Group:
    def __init__(self, gname):
        assert gname
        insts, self.desc = get_asg_insts(gname)
        self.instances = [Instance(desc=inst) for inst in insts]

    def instance_ids(self):
        return (inst.instance_id() for inst in self.instances)

    def version_ids_set(self):
        return set(map(lambda instance: instance.version_id(), self.instances))

    def version_id(self):
        return get_hash(self.version_ids_set())

    def spec_id(self):
        return get_hash({'insts': set(map(lambda instance: instance.spec_id(), self.instances)),
                         'desired_capacity': self.desc['DesiredCapacity']})

    def runtime_id(self):
        return get_hash(set(map(lambda instance: instance.runtime_id(), self.instances)))

    def runtime_count(self):
        return len(self.instances)


class Instance:
    def __init__(self, desc):
        assert desc
        self.desc = desc

    def instance_id(self):
        return self.desc['InstanceId']

    def version_id(self):
        return self.desc['ImageId']

    def spec_id(self):
        return '{} {}'.format(self.version_id(), self.desc['InstanceType'])

    def runtime_id(self):
        return self.instance_id()


class A(adjust.Adjust):

    @staticmethod
    def get_cfg_target_asgs():
        return sorted(list(filter(str, map(lambda g: g.strip(), (cfg.get('asg', '') if cfg.get('asg') is not None else '').split(',')))))

    @staticmethod
    def get_cfg_ref_asgs():
        v = cfg.get('control', {}).get('userdata', {}).get('deployment', '')
        return sorted(list(filter(str, map(lambda g: g.strip(), (v if v is not None else '').split(',')))))

    def get_cfg_all_asgs(self):
        return (*self.get_cfg_target_asgs(), *self.get_cfg_ref_asgs())

    @staticmethod
    def get_asg_activities(gname, period=3600):
        start = time()
        token = None
        while True:
            kwargs = {'AutoScalingGroupName': gname,
                      **({'NextToken': token} if token is not None else {})}
            resp = asg.describe_scaling_activities(**kwargs)
            token = resp.get('NextToken')
            if resp.get('Activities'):
                for activity in resp['Activities']:
                    if (start - activity['StartTime'].timestamp()) <= period:
                        yield activity
                        continue
                    break
            break

    def get_scaling_act_ids(self, gnames):
        return list(itertools.chain(*((a["ActivityId"] for a in self.get_asg_activities(gname)
                                       if a["StatusCode"] not in ACT_FINAL_STATUSES)
                                      for gname in gnames)))

    def wait_for_scaling_activities(self, gnames, progr=None, wait_time=None):
        if wait_time is None:
            biggest_cooldown = max(group['DefaultCooldown'] for group in
                                   asg.describe_auto_scaling_groups(AutoScalingGroupNames=gnames)['AutoScalingGroups'])
            wait_time = max(biggest_cooldown + 5, 60)
        try:
            start = time()
            while True:
                ids = self.get_scaling_act_ids(gnames)
                if ids:
                    if progr:
                        progr.report('Waiting for {} activities to complete.'.format(len(ids)))
                    wait_for_activities(ids, timeout=600)
                    start = time()
                else:
                    expired = (time() - start) > wait_time
                    if expired:
                        break
                    sleep(5)
        except BOTO_EXCEPTIONS as e:
            raise Exception('Failed to wait for target and reference ASGs activities to complete. '
                            'Exception -> {}: {}'.format(e.__class__.__name__, str(e)))
        except ASGActivityTimeOutError:
            raise ASGActivityTimeOutError('Timed out waiting for incomplete activities to resolve. '
                                          'Activity ids that were still in progress: {}'
                                          ''.format(self.get_scaling_act_ids(gnames)))

    def scale_to_one_if_needed(self, gname):
        on_fail = cfg.get('control', {}).get('on_fail')
        if on_fail == 'destroy' and get_group(gname)['DesiredCapacity'] == 0:
            asg.update_auto_scaling_group(AutoScalingGroupName=gname, DesiredCapacity=1)
            return True
        return False

    def get_mon_insts(self):
        ret = {}
        gnames = self.get_cfg_target_asgs()
        ref_gnames = sorted(list(filter(str, map(lambda g: g.strip(), (cfg.get('ref_asg') if cfg.get('ref_asg') is not None else '').split(',')))))
        inst_param = cfg.get('asg_inst_param', 'InstanceId')
        for name in gnames:
            insts, _ = get_asg_insts(name)
            insts = map(lambda i: i[inst_param], insts)
            ret.setdefault('instance_ids', []).extend(insts)
        for name in ref_gnames:
            insts, _ = get_asg_insts(name)
            insts = map(lambda i: i[inst_param], insts)
            ret.setdefault('ref_instance_ids', []).extend(insts)
        assert ret['ref_instance_ids'], 'Reference ASGs are empty. ' \
                                        'There should be at least one instance in the specified ASGs.'
        return ret

    def monitor(self):
        target_app = App(self.get_cfg_target_asgs())
        try:
            ref_app = App(self.get_cfg_ref_asgs()) if self.get_cfg_ref_asgs() else None
        except ASGUnavailableException as e:
            raise RefASGUnavailableException(original=e.original)
        ret = {
            'spec_id': target_app.spec_id(),
            'runtime_id': target_app.runtime_id(),
            'version_id': target_app.version_id(),
            **({'ref_spec_id': ref_app.spec_id(),
                'ref_runtime_id': ref_app.runtime_id(),
                'ref_runtime_count': ref_app.runtime_count(),
                'ref_version_id': ref_app.version_id()} if ref_app else {})
        }
        return ret, target_app, ref_app

    def remediate(self, types_per_group, progr):
        asgs = self.get_cfg_target_asgs()
        on_fail = cfg.get('control', {}).get('on_fail', 'keep')
        try:
            if on_fail == 'destroy':
                for g in asgs:
                    asg.update_auto_scaling_group(AutoScalingGroupName=g, DesiredCapacity=0, MinSize=0)
            if on_fail == 'rollback':
                for gname in asgs:
                    itype = types_per_group[gname]
                    set_running_inst_type(gname, itype, progr)
        except Exception as e:
            raise Exception('Failed to remediate adjust failure for groups {}. '
                            'Exception -> {}: {}'.format(asg, e.__class__.__name__, str(e)))
        try:
            self.wait_for_scaling_activities(asgs, progr=progr)
        except Exception:
            pass

    def settle(self, progr, period=SETTLE_TIME):
        all_asgs = self.get_cfg_all_asgs()
        try:
            mon0, target_app0, _ = self.monitor()
        except RefASGUnavailableException as e:
            self.wait_for_scaling_activities(all_asgs, progr=progr)
            raise AdjustError("unable to query reference asg(s) for monitoring during settlement period; "
                              "exception: {}".format(str(e.original)),
                              status="aborted", reason="ref-app-unavailable")
        except Exception as e:
            raise AdjustError("Could not fetch all monitoring data due to: {}: {}".format(e.__class__.__name__,
                                                                                          str(e)))

        # TODO: remove progress report below. Is only used for debug
        progr.report('Canary Inst Id(s) {}'.format(target_app0.instance_ids))

        expired = False
        start = time()
        # Check-failure counters and checkboxes
        new_inst_ids = set()
        target_asg_restarted_once = False
        # Settlement cycle over a period of time (arg period) every X (SETTLE_CHECK_TIME) seconds
        while not expired:
            try:
                # Get fresh env state for monitoring checks
                mon, target_app, ref_app = self.monitor()
            except RefASGUnavailableException as e:
                raise AdjustError("unable to query reference asg(s) for monitoring during settlement period; "
                                  "exception: {}".format(str(e.original)),
                                  status="aborted", reason="ref-app-unavailable")
            except Exception as e:
                raise AdjustError("Could not fetch all monitoring data due to: {}: {}".format(e.__class__.__name__,
                                                                                              str(e)))
            if mon['spec_id'] != mon0['spec_id'] or mon['version_id'] != mon0['version_id']:
                self.wait_for_scaling_activities(all_asgs, progr=progr)
                progr.report("WARNING: target asg configuration was modified unexpectedly: source asg={}\n target asg={}".format(mon0, mon))
            new_inst_ids.update(target_app.new_instances(target_app0))
            if new_inst_ids:
                target_asg_restarted_once = True
                if target_app.gone_instances(new_inst_ids):
                    raise AdjustError('some of the target asg {} instances have been re-spawned twice or more '
                                      'during settlement period; it is most likely a fail-restart cycle'
                                      ''.format(self.get_cfg_target_asgs()), status="rejected", reason="unstable")
            if ref_app:
                if len(ref_app.version_ids_set()) > 1:
                    self.wait_for_scaling_activities(all_asgs, progr=progr)
                    raise AdjustError("reference application software version is not consistent among its replicas",
                                      status="aborted", reason="ref-app-inconsistent")
                if mon["version_id"] != mon["ref_version_id"]:
                    self.wait_for_scaling_activities(all_asgs, progr=progr)
                    raise AdjustError("Target asg(s) software version is different from one in reference asg(s).",
                                      status="rejected", reason="version-mismatch")
                if mon["ref_spec_id"] != mon0["ref_spec_id"]:
                    self.wait_for_scaling_activities(all_asgs, progr=progr)
                    raise AdjustError("reference application configuration was modified unexpectedly",
                                      status="transient-failure", reason="ref-app-update")
                if mon["ref_runtime_count"] != mon0["ref_runtime_count"]:
                    self.wait_for_scaling_activities(all_asgs, progr=progr)
                    raise AdjustError("reference application has scaled during settlement period",
                                      status="transient-failure", reason="ref-app-scale")
            mon0, target_app0 = mon, target_app
            progr.set((time() - start) / period)
            progr.report('Settlement phase is in progress. Started {:.0f} seconds ago. {:.0f} seconds to go. '
                         'Total is {:d} seconds.'.format((time() - start), max(0.0, period - (time() - start)),
                                                         period))
            expired = (time() - start) >= period  # Update settlement period status (i.e. whether done or not)
            sleep(SETTLE_CHECK_TIME)  # Sleep before checking again
        if target_asg_restarted_once:
            raise AdjustError("target asg restart detected", status="transient-failure", reason="app-restart")
        return mon0

    def query(self):
        try:
            m, _, _ = self.monitor()
        except Exception as e:
            raise Exception("Could not fetch all monitoring data due to: {}: {}".format(e.__class__.__name__, str(e)))
        m = {**m, **self.get_mon_insts()} if cfg.get('ref_asg') is not None else m
        gc = lambda v: dict(settings=dict(inst_type=dict(value=v, type="enum", values=list(INST_TYPES), unit="ec2")))
        comps = {gname: gc(q(gname)) for gname in self.get_cfg_target_asgs()}
        return {"application": {"components": comps}, "monitoring": m}

    def adjust(self, data=None):
        comps = self.input_data["application"].get("components", {}).copy()
        # print (self.input_data, file=sys.stderr)
        groups = self.get_cfg_target_asgs()
        lst = [(g, comps.pop(g)) for g in groups if comps.get(g)]
        # check for components not in 'groups'
        if comps:
            # return  {"status":"failed", "message":}
            # FIXME: base class should support custom exceptions and/or allow returning data from adjust()
            raise Exception("input data contains unknown components: "+ repr(list(data.keys())))
        # FIXME: correct behavior on 'extra' data (e.g. unknown comps or unknown settings) - ignore or fail?

        # If the app is canary mode (ref_asg is non-empty) and single component
        # (sanity check), then set the ASG min_size=0 so the canary can be placed
        # in standby mode even if the min_size is presently 1
        if (cfg.get('ref_asg') and len(groups)==1 and len(lst)==1):
            g,v = lst[0]
            r = asg.update_auto_scaling_group(AutoScalingGroupName=g, MinSize=0)
            print("DBG:  resp for ASG {} update min_size=0:  {}".format(g, r), file=sys.stderr)

        init_first_inst_types_per_group = {}
        progr = Progress()
        progr.start_timer()
        try:
            grp_weight = 0.9/float(len(lst)) # empty settings counted as well (cosmetic, will cause uneven progress advance, FIXME)
            for n,(g,v) in enumerate(lst):
                progr.set(grp_weight * float(n))
                if "settings" not in v: continue
                t = v["settings"].get("inst_type", None)
                if not t:
                    continue # not set
                with progr.stage(grp_weight) as p_stage:
                    try:
                        if self.scale_to_one_if_needed(g):
                            self.wait_for_scaling_activities([g], wait_time=60)
                        init_first_inst_types_per_group[g] = next(iter(get_insts_from_resp(
                            ec2.describe_instances(InstanceIds=[get_group(g)["Instances"][0]["InstanceId"]]))))[
                            "InstanceType"]
                        set_running_inst_type(g, t["value"], p_stage, batch = cfg.get("batch_size", 1)) # TODO: check t["value"] exists
                    except AWS_EXCEPTIONS as e:
                        raise AdjustError('failed to adjust instances of target asg "{}"; exception: {}'.format(g, str(e)),
                                          status="failed", reason="adjust-failed")

            with progr.stage(0.1) as p_stage:
                mon = self.settle(p_stage, self.input_data.get('control', {}).get('settlement', SETTLE_TIME))
        except AdjustError as e:
            if any((e.status == "rejected",
                    e.reason in ("adjust-failed", "start-failed"))):
                self.remediate(init_first_inst_types_per_group, progr)
            raise
        finally:
            progr.stop_timer()
        return {"status":"ok", "monitoring": mon}

if __name__ == "__main__":
    # config section 'ec2asg'
    # servo-ec2asg
    cfg = read_config()
    # TODO (probably best to add to base class: check for required settings)
    i = A("1", "(todo - help text)", False)
    i.run()
